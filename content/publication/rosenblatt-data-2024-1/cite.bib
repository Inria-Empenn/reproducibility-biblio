@article{rosenblatt_data_2024-1,
 abstract = {Abstract
Predictive modeling is a central technique in neuroimaging to identify brain-behavior relationships and test their generalizability to unseen data. However, data leakage undermines the validity of predictive models by breaching the separation between training and test data. Leakage is always an incorrect practice but still pervasive in machine learning. Understanding its effects on neuroimaging predictive models can inform how leakage affects existing literature. Here, we investigate the effects of five forms of leakage–involving feature selection, covariate correction, and dependence between subjects–on functional and structural connectome-based machine learning models across four datasets and three phenotypes. Leakage via feature selection and repeated subjects drastically inflates prediction performance, whereas other forms of leakage have minor effects. Furthermore, small datasets exacerbate the effects of leakage. Overall, our results illustrate the variable effects of leakage and underscore the importance of avoiding data leakage to improve the validity and reproducibility of predictive modeling.},
 author = {Rosenblatt, Matthew and Tejavibulya, Link and Jiang, Rongtao and Noble, Stephanie and Scheinost, Dustin},
 doi = {10.1038/s41467-024-46150-w},
 file = {Rosenblatt et al. - 2024 - Data leakage inflates prediction performance in co.pdf:/home/alpron/Zotero/storage/P3NIEWBK/Rosenblatt et al. - 2024 - Data leakage inflates prediction performance in co.pdf:application/pdf},
 issn = {2041-1723},
 journal = {Nature Communications},
 language = {en},
 month = {February},
 number = {1},
 pages = {1829},
 title = {Data leakage inflates prediction performance in connectome-based machine learning models},
 url = {https://www.nature.com/articles/s41467-024-46150-w},
 urldate = {2024-07-15},
 volume = {15},
 year = {2024}
}
